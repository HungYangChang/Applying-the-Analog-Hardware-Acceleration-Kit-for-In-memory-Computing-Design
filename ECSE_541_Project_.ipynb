{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ECSE_541_Project .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ1PQn6JMpbU"
      },
      "source": [
        "# Library/Dependency Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlYoU_FUdxal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61305d32-b426-489d-a402-029435405b51"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Check device\n",
        "USE_CUDA = 0\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        " USE_CUDA = 1\n",
        " print(f\"Nvidia Cuda/GPU is available!\")\n",
        "else:\n",
        "  print (\"not available\") \n",
        " \n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        " print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nvidia Cuda/GPU is available!\n",
            "Sat Dec  5 15:01:10 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    29W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x54htSB2CqJb",
        "outputId": "d10664af-ab9d-482a-8b28-bd91375519a3"
      },
      "source": [
        "# Creating python virtual env for aihwkit\n",
        "%%script bash\n",
        "apt-get install python3-venv\n",
        "python3 -m venv aihwkit_env\n",
        "cd aihwkit_env/\n",
        "source bin/activate\n",
        "git clone https://github.com/IBM/aihwkit.git\n",
        "cd aihwkit\n",
        "# ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3.6-venv\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-venv python3.6-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 1,660 kB of archives.\n",
            "After this operation, 1,902 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.4 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3.6-venv amd64 3.6.9-1~18.04ubuntu1.3 [6,180 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-venv amd64 3.6.7-1~18.04 [1,208 B]\n",
            "Fetched 1,660 kB in 3s (555 kB/s)\n",
            "Selecting previously unselected package python-pip-whl.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 144865 files and directories currently installed.)\r\n",
            "Preparing to unpack .../python-pip-whl_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\r\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\r\n",
            "Selecting previously unselected package python3.6-venv.\r\n",
            "Preparing to unpack .../python3.6-venv_3.6.9-1~18.04ubuntu1.3_amd64.deb ...\r\n",
            "Unpacking python3.6-venv (3.6.9-1~18.04ubuntu1.3) ...\r\n",
            "Selecting previously unselected package python3-venv.\r\n",
            "Preparing to unpack .../python3-venv_3.6.7-1~18.04_amd64.deb ...\r\n",
            "Unpacking python3-venv (3.6.7-1~18.04) ...\r\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\r\n",
            "Setting up python3.6-venv (3.6.9-1~18.04ubuntu1.3) ...\r\n",
            "Setting up python3-venv (3.6.7-1~18.04) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'aihwkit'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItgRdAxaN9MY",
        "outputId": "330aec55-171b-4134-b2f1-bc299bf2f544"
      },
      "source": [
        "# Installing dependencies in the virtual environment\n",
        "%%script bash\n",
        "sudo apt-get install ninja-build\n",
        "sudo apt-get install libopenblas-dev\n",
        "pip install pybind11 scikit-build\n",
        "pip install cmake --upgrade\n",
        "pip install aihwkit\n",
        "pip list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  ninja-build\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 93.3 kB of archives.\n",
            "After this operation, 296 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ninja-build amd64 1.8.2-1 [93.3 kB]\n",
            "Fetched 93.3 kB in 1s (70.0 kB/s)\n",
            "Selecting previously unselected package ninja-build.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 144903 files and directories currently installed.)\r\n",
            "Preparing to unpack .../ninja-build_1.8.2-1_amd64.deb ...\r\n",
            "Unpacking ninja-build (1.8.2-1) ...\r\n",
            "Setting up ninja-build (1.8.2-1) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
            "Collecting pybind11\n",
            "  Downloading https://files.pythonhosted.org/packages/00/84/fc9dc13ee536ba5e6b8fd10ce368fea5b738fe394c3b296cde7c9b144a92/pybind11-2.6.1-py2.py3-none-any.whl (188kB)\n",
            "Collecting scikit-build\n",
            "  Downloading https://files.pythonhosted.org/packages/78/c9/7c2c7397ea64e36ebb292446896edcdecbb8c1aa6b9a1a32f6f67984c3df/scikit_build-0.11.1-py2.py3-none-any.whl (72kB)\n",
            "Requirement already satisfied: setuptools>=28.0.0; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from scikit-build) (50.3.2)\n",
            "Requirement already satisfied: wheel>=0.29.0 in /usr/local/lib/python3.6/dist-packages (from scikit-build) (0.35.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from scikit-build) (20.4)\n",
            "Collecting distro\n",
            "  Downloading https://files.pythonhosted.org/packages/25/b7/b3c4270a11414cb22c6352ebc7a83aaa3712043be29daa05018fd5a5c956/distro-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->scikit-build) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->scikit-build) (2.4.7)\n",
            "Installing collected packages: pybind11, distro, scikit-build\n",
            "Successfully installed distro-1.5.0 pybind11-2.6.1 scikit-build-0.11.1\n",
            "Collecting cmake\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/c5/9a07d851bf8356dba2871f141f3e5e8d390995687be20316041a1e564d4c/cmake-3.18.4.post1-py3-none-manylinux1_x86_64.whl (17.7MB)\n",
            "Installing collected packages: cmake\n",
            "  Found existing installation: cmake 3.12.0\n",
            "    Uninstalling cmake-3.12.0:\n",
            "      Successfully uninstalled cmake-3.12.0\n",
            "Successfully installed cmake-3.18.4.post1\n",
            "Collecting aihwkit\n",
            "  Downloading https://files.pythonhosted.org/packages/82/74/05a214ef401fcb9bedeb7a0fd1003e3bf0cd3a1567a6fc2838ac890722e5/aihwkit-0.2.1-cp36-cp36m-manylinux2014_x86_64.whl (10.8MB)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.6/dist-packages (from aihwkit) (1.18.5)\n",
            "Collecting dataclasses==0.7; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
            "Collecting torch==1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->aihwkit) (0.16.0)\n",
            "Installing collected packages: dataclasses, torch, aihwkit\n",
            "  Found existing installation: dataclasses 0.8\n",
            "    Uninstalling dataclasses-0.8:\n",
            "      Successfully uninstalled dataclasses-0.8\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "Successfully installed aihwkit-0.2.1 dataclasses-0.7 torch-1.6.0\n",
            "Package                       Version        \n",
            "----------------------------- ---------------\n",
            "absl-py                       0.10.0         \n",
            "aihwkit                       0.2.1          \n",
            "alabaster                     0.7.12         \n",
            "albumentations                0.1.12         \n",
            "altair                        4.1.0          \n",
            "argon2-cffi                   20.1.0         \n",
            "asgiref                       3.3.1          \n",
            "astor                         0.8.1          \n",
            "astropy                       4.1            \n",
            "astunparse                    1.6.3          \n",
            "async-generator               1.10           \n",
            "atari-py                      0.2.6          \n",
            "atomicwrites                  1.4.0          \n",
            "attrs                         20.3.0         \n",
            "audioread                     2.1.9          \n",
            "autograd                      1.3            \n",
            "Babel                         2.9.0          \n",
            "backcall                      0.2.0          \n",
            "beautifulsoup4                4.6.3          \n",
            "bleach                        3.2.1          \n",
            "blis                          0.4.1          \n",
            "bokeh                         2.1.1          \n",
            "Bottleneck                    1.3.2          \n",
            "branca                        0.4.1          \n",
            "bs4                           0.0.1          \n",
            "CacheControl                  0.12.6         \n",
            "cachetools                    4.1.1          \n",
            "catalogue                     1.0.0          \n",
            "certifi                       2020.11.8      \n",
            "cffi                          1.14.3         \n",
            "chainer                       7.4.0          \n",
            "chardet                       3.0.4          \n",
            "click                         7.1.2          \n",
            "cloudpickle                   1.3.0          \n",
            "cmake                         3.18.4.post1   \n",
            "cmdstanpy                     0.9.5          \n",
            "colorlover                    0.3.0          \n",
            "community                     1.0.0b1        \n",
            "contextlib2                   0.5.5          \n",
            "convertdate                   2.3.0          \n",
            "coverage                      3.7.1          \n",
            "coveralls                     0.5            \n",
            "crcmod                        1.7            \n",
            "cufflinks                     0.17.3         \n",
            "cupy-cuda101                  7.4.0          \n",
            "cvxopt                        1.2.5          \n",
            "cvxpy                         1.0.31         \n",
            "cycler                        0.10.0         \n",
            "cymem                         2.0.4          \n",
            "Cython                        0.29.21        \n",
            "daft                          0.0.4          \n",
            "dask                          2.12.0         \n",
            "dataclasses                   0.7            \n",
            "datascience                   0.10.6         \n",
            "debugpy                       1.0.0          \n",
            "decorator                     4.4.2          \n",
            "defusedxml                    0.6.0          \n",
            "descartes                     1.1.0          \n",
            "dill                          0.3.3          \n",
            "distributed                   1.25.3         \n",
            "distro                        1.5.0          \n",
            "Django                        3.1.3          \n",
            "dlib                          19.18.0        \n",
            "dm-tree                       0.1.5          \n",
            "docopt                        0.6.2          \n",
            "docutils                      0.16           \n",
            "dopamine-rl                   1.0.5          \n",
            "earthengine-api               0.1.238        \n",
            "easydict                      1.9            \n",
            "ecos                          2.0.7.post1    \n",
            "editdistance                  0.5.3          \n",
            "en-core-web-sm                2.2.5          \n",
            "entrypoints                   0.3            \n",
            "ephem                         3.7.7.1        \n",
            "et-xmlfile                    1.0.1          \n",
            "fa2                           0.3.5          \n",
            "fancyimpute                   0.4.3          \n",
            "fastai                        1.0.61         \n",
            "fastdtw                       0.3.4          \n",
            "fastprogress                  1.0.0          \n",
            "fastrlock                     0.5            \n",
            "fbprophet                     0.7.1          \n",
            "feather-format                0.4.1          \n",
            "filelock                      3.0.12         \n",
            "firebase-admin                4.4.0          \n",
            "fix-yahoo-finance             0.0.22         \n",
            "Flask                         1.1.2          \n",
            "flatbuffers                   1.12           \n",
            "folium                        0.8.3          \n",
            "future                        0.16.0         \n",
            "gast                          0.3.3          \n",
            "GDAL                          2.2.2          \n",
            "gdown                         3.6.4          \n",
            "gensim                        3.6.0          \n",
            "geographiclib                 1.50           \n",
            "geopy                         1.17.0         \n",
            "gin-config                    0.3.0          \n",
            "glob2                         0.7            \n",
            "google                        2.0.3          \n",
            "google-api-core               1.16.0         \n",
            "google-api-python-client      1.7.12         \n",
            "google-auth                   1.17.2         \n",
            "google-auth-httplib2          0.0.4          \n",
            "google-auth-oauthlib          0.4.2          \n",
            "google-cloud-bigquery         1.21.0         \n",
            "google-cloud-bigquery-storage 1.1.0          \n",
            "google-cloud-core             1.0.3          \n",
            "google-cloud-datastore        1.8.0          \n",
            "google-cloud-firestore        1.7.0          \n",
            "google-cloud-language         1.2.0          \n",
            "google-cloud-storage          1.18.1         \n",
            "google-cloud-translate        1.5.0          \n",
            "google-colab                  1.0.0          \n",
            "google-pasta                  0.2.0          \n",
            "google-resumable-media        0.4.1          \n",
            "googleapis-common-protos      1.52.0         \n",
            "googledrivedownloader         0.4            \n",
            "graphviz                      0.10.1         \n",
            "grpcio                        1.33.2         \n",
            "gspread                       3.0.1          \n",
            "gspread-dataframe             3.0.8          \n",
            "gym                           0.17.3         \n",
            "h5py                          2.10.0         \n",
            "HeapDict                      1.0.1          \n",
            "holidays                      0.10.3         \n",
            "holoviews                     1.13.5         \n",
            "html5lib                      1.0.1          \n",
            "httpimport                    0.5.18         \n",
            "httplib2                      0.17.4         \n",
            "httplib2shim                  0.0.3          \n",
            "humanize                      0.5.1          \n",
            "hyperopt                      0.1.2          \n",
            "ideep4py                      2.0.0.post3    \n",
            "idna                          2.10           \n",
            "image                         1.5.33         \n",
            "imageio                       2.4.1          \n",
            "imagesize                     1.2.0          \n",
            "imbalanced-learn              0.4.3          \n",
            "imblearn                      0.0            \n",
            "imgaug                        0.2.9          \n",
            "importlib-metadata            2.0.0          \n",
            "importlib-resources           3.3.0          \n",
            "imutils                       0.5.3          \n",
            "inflect                       2.1.0          \n",
            "iniconfig                     1.1.1          \n",
            "intel-openmp                  2020.0.133     \n",
            "intervaltree                  2.1.0          \n",
            "ipykernel                     4.10.1         \n",
            "ipython                       5.5.0          \n",
            "ipython-genutils              0.2.0          \n",
            "ipython-sql                   0.3.9          \n",
            "ipywidgets                    7.5.1          \n",
            "itsdangerous                  1.1.0          \n",
            "jax                           0.2.6          \n",
            "jaxlib                        0.1.57+cuda101 \n",
            "jdcal                         1.4.1          \n",
            "jedi                          0.17.2         \n",
            "jieba                         0.42.1         \n",
            "Jinja2                        2.11.2         \n",
            "joblib                        0.17.0         \n",
            "jpeg4py                       0.1.4          \n",
            "jsonschema                    2.6.0          \n",
            "jupyter                       1.0.0          \n",
            "jupyter-client                5.3.5          \n",
            "jupyter-console               5.2.0          \n",
            "jupyter-core                  4.7.0          \n",
            "jupyterlab-pygments           0.1.2          \n",
            "kaggle                        1.5.9          \n",
            "kapre                         0.1.3.1        \n",
            "Keras                         2.4.3          \n",
            "Keras-Preprocessing           1.1.2          \n",
            "keras-vis                     0.4.1          \n",
            "kiwisolver                    1.3.1          \n",
            "knnimpute                     0.1.0          \n",
            "korean-lunar-calendar         0.2.1          \n",
            "librosa                       0.6.3          \n",
            "lightgbm                      2.2.3          \n",
            "llvmlite                      0.31.0         \n",
            "lmdb                          0.99           \n",
            "lucid                         0.3.8          \n",
            "LunarCalendar                 0.0.9          \n",
            "lxml                          4.2.6          \n",
            "Markdown                      3.3.3          \n",
            "MarkupSafe                    1.1.1          \n",
            "matplotlib                    3.2.2          \n",
            "matplotlib-venn               0.11.6         \n",
            "missingno                     0.4.2          \n",
            "mistune                       0.8.4          \n",
            "mizani                        0.6.0          \n",
            "mkl                           2019.0         \n",
            "mlxtend                       0.14.0         \n",
            "more-itertools                8.6.0          \n",
            "moviepy                       0.2.3.5        \n",
            "mpmath                        1.1.0          \n",
            "msgpack                       1.0.0          \n",
            "multiprocess                  0.70.11.1      \n",
            "multitasking                  0.0.9          \n",
            "murmurhash                    1.0.4          \n",
            "music21                       5.5.0          \n",
            "natsort                       5.5.0          \n",
            "nbclient                      0.5.1          \n",
            "nbconvert                     5.6.1          \n",
            "nbformat                      5.0.8          \n",
            "nest-asyncio                  1.4.3          \n",
            "networkx                      2.5            \n",
            "nibabel                       3.0.2          \n",
            "nltk                          3.2.5          \n",
            "notebook                      5.3.1          \n",
            "np-utils                      0.5.12.1       \n",
            "numba                         0.48.0         \n",
            "numexpr                       2.7.1          \n",
            "numpy                         1.18.5         \n",
            "nvidia-ml-py3                 7.352.0        \n",
            "oauth2client                  4.1.3          \n",
            "oauthlib                      3.1.0          \n",
            "okgrade                       0.4.3          \n",
            "opencv-contrib-python         4.1.2.30       \n",
            "opencv-python                 4.1.2.30       \n",
            "openpyxl                      2.5.9          \n",
            "opt-einsum                    3.3.0          \n",
            "osqp                          0.6.1          \n",
            "packaging                     20.4           \n",
            "palettable                    3.3.0          \n",
            "pandas                        1.1.4          \n",
            "pandas-datareader             0.9.0          \n",
            "pandas-gbq                    0.13.3         \n",
            "pandas-profiling              1.4.1          \n",
            "pandocfilters                 1.4.3          \n",
            "panel                         0.9.7          \n",
            "param                         1.10.0         \n",
            "parso                         0.7.1          \n",
            "pathlib                       1.0.1          \n",
            "patsy                         0.5.1          \n",
            "pexpect                       4.8.0          \n",
            "pickleshare                   0.7.5          \n",
            "Pillow                        7.0.0          \n",
            "pip                           19.3.1         \n",
            "pip-tools                     4.5.1          \n",
            "plac                          1.1.3          \n",
            "plotly                        4.4.1          \n",
            "plotnine                      0.6.0          \n",
            "pluggy                        0.7.1          \n",
            "portpicker                    1.3.1          \n",
            "prefetch-generator            1.0.1          \n",
            "preshed                       3.0.4          \n",
            "prettytable                   2.0.0          \n",
            "progressbar2                  3.38.0         \n",
            "prometheus-client             0.9.0          \n",
            "promise                       2.3            \n",
            "prompt-toolkit                1.0.18         \n",
            "protobuf                      3.12.4         \n",
            "psutil                        5.4.8          \n",
            "psycopg2                      2.7.6.1        \n",
            "ptyprocess                    0.6.0          \n",
            "py                            1.9.0          \n",
            "pyarrow                       0.14.1         \n",
            "pyasn1                        0.4.8          \n",
            "pyasn1-modules                0.2.8          \n",
            "pybind11                      2.6.1          \n",
            "pycocotools                   2.0.2          \n",
            "pycparser                     2.20           \n",
            "pyct                          0.4.8          \n",
            "pydata-google-auth            1.1.0          \n",
            "pydot                         1.3.0          \n",
            "pydot-ng                      2.0.0          \n",
            "pydotplus                     2.0.2          \n",
            "PyDrive                       1.3.1          \n",
            "pyemd                         0.5.1          \n",
            "pyglet                        1.5.0          \n",
            "Pygments                      2.6.1          \n",
            "pygobject                     3.26.1         \n",
            "pymc3                         3.7            \n",
            "PyMeeus                       0.3.7          \n",
            "pymongo                       3.11.1         \n",
            "pymystem3                     0.2.0          \n",
            "PyOpenGL                      3.1.5          \n",
            "pyparsing                     2.4.7          \n",
            "pyrsistent                    0.17.3         \n",
            "pysndfile                     1.3.8          \n",
            "PySocks                       1.7.1          \n",
            "pystan                        2.19.1.1       \n",
            "pytest                        3.6.4          \n",
            "python-apt                    1.6.5+ubuntu0.3\n",
            "python-chess                  0.23.11        \n",
            "python-dateutil               2.8.1          \n",
            "python-louvain                0.14           \n",
            "python-slugify                4.0.1          \n",
            "python-utils                  2.4.0          \n",
            "pytz                          2018.9         \n",
            "pyviz-comms                   0.7.6          \n",
            "PyWavelets                    1.1.1          \n",
            "PyYAML                        3.13           \n",
            "pyzmq                         20.0.0         \n",
            "qtconsole                     5.0.1          \n",
            "QtPy                          1.9.0          \n",
            "regex                         2019.12.20     \n",
            "requests                      2.23.0         \n",
            "requests-oauthlib             1.3.0          \n",
            "resampy                       0.2.2          \n",
            "retrying                      1.3.3          \n",
            "rpy2                          3.2.7          \n",
            "rsa                           4.6            \n",
            "scikit-build                  0.11.1         \n",
            "scikit-image                  0.16.2         \n",
            "scikit-learn                  0.22.2.post1   \n",
            "scipy                         1.4.1          \n",
            "screen-resolution-extra       0.0.0          \n",
            "scs                           2.1.2          \n",
            "seaborn                       0.11.0         \n",
            "Send2Trash                    1.5.0          \n",
            "setuptools                    50.3.2         \n",
            "setuptools-git                1.2            \n",
            "Shapely                       1.7.1          \n",
            "simplegeneric                 0.8.1          \n",
            "six                           1.15.0         \n",
            "sklearn                       0.0            \n",
            "sklearn-pandas                1.8.0          \n",
            "slugify                       0.0.1          \n",
            "smart-open                    3.0.0          \n",
            "snowballstemmer               2.0.0          \n",
            "sortedcontainers              2.3.0          \n",
            "spacy                         2.2.4          \n",
            "Sphinx                        1.8.5          \n",
            "sphinxcontrib-serializinghtml 1.1.4          \n",
            "sphinxcontrib-websupport      1.2.4          \n",
            "SQLAlchemy                    1.3.20         \n",
            "sqlparse                      0.4.1          \n",
            "srsly                         1.0.4          \n",
            "statsmodels                   0.10.2         \n",
            "sympy                         1.1.1          \n",
            "tables                        3.4.4          \n",
            "tabulate                      0.8.7          \n",
            "tblib                         1.7.0          \n",
            "tensorboard                   2.3.0          \n",
            "tensorboard-plugin-wit        1.7.0          \n",
            "tensorboardcolab              0.0.22         \n",
            "tensorflow                    2.3.0          \n",
            "tensorflow-addons             0.8.3          \n",
            "tensorflow-datasets           4.0.1          \n",
            "tensorflow-estimator          2.3.0          \n",
            "tensorflow-gcs-config         2.3.0          \n",
            "tensorflow-hub                0.10.0         \n",
            "tensorflow-metadata           0.25.0         \n",
            "tensorflow-privacy            0.2.2          \n",
            "tensorflow-probability        0.11.0         \n",
            "termcolor                     1.1.0          \n",
            "terminado                     0.9.1          \n",
            "testpath                      0.4.4          \n",
            "text-unidecode                1.3            \n",
            "textblob                      0.15.3         \n",
            "textgenrnn                    1.4.1          \n",
            "Theano                        1.0.5          \n",
            "thinc                         7.4.0          \n",
            "tifffile                      2020.9.3       \n",
            "toml                          0.10.2         \n",
            "toolz                         0.11.1         \n",
            "torch                         1.6.0          \n",
            "torchsummary                  1.5.1          \n",
            "torchtext                     0.3.1          \n",
            "torchvision                   0.8.1+cu101    \n",
            "tornado                       5.1.1          \n",
            "tqdm                          4.41.1         \n",
            "traitlets                     4.3.3          \n",
            "tweepy                        3.6.0          \n",
            "typeguard                     2.7.1          \n",
            "typing-extensions             3.7.4.3        \n",
            "tzlocal                       1.5.1          \n",
            "umap-learn                    0.4.6          \n",
            "uritemplate                   3.0.1          \n",
            "urllib3                       1.24.3         \n",
            "vega-datasets                 0.8.0          \n",
            "wasabi                        0.8.0          \n",
            "wcwidth                       0.2.5          \n",
            "webencodings                  0.5.1          \n",
            "Werkzeug                      1.0.1          \n",
            "wheel                         0.35.1         \n",
            "widgetsnbextension            3.5.1          \n",
            "wordcloud                     1.5.0          \n",
            "wrapt                         1.12.1         \n",
            "xarray                        0.15.1         \n",
            "xgboost                       0.90           \n",
            "xkit                          0.0.0          \n",
            "xlrd                          1.1.0          \n",
            "xlwt                          1.3.0          \n",
            "yellowbrick                   0.9.1          \n",
            "zict                          2.0.0          \n",
            "zipp                          3.4.0          \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "ERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.6.0 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2XSEk6VGkXe",
        "outputId": "db08159e-37c6-4fb9-88cb-1507990c915c"
      },
      "source": [
        "# Building the library\n",
        "%%script bash\n",
        "cd aihwkit_env/aihwkit/\n",
        "make clean\n",
        "python setup.py build_ext --inplace -DUSE_CUDA=ON -DRPU_CUDA_ARCHITECTURES=\"60;70\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python setup.py clean\n",
            "running clean\n",
            "rm -rf _skbuild\n",
            "rm -f src/aihwkit/simulator/rpu_base.*.so\n",
            "Not searching for unused variables given on the command line.\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/aihwkit_env/aihwkit/_cmake_test_compile/build\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Invoking cmake through scikit-build\n",
            "-- The BLAS backend of choice:OpenBLAS\n",
            "-- Found OpenBLAS libraries: /usr/lib/x86_64-linux-gnu/libopenblas.so\n",
            "-- Found OpenBLAS include: /usr/include/x86_64-linux-gnu\n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so (found version \"3.6.9\") \n",
            "-- Found PythonInterp: /usr/bin/python3 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /usr/local/lib/python3.6/dist-packages/pybind11/include (found version \"2.6.1\" )\n",
            "-- Found Python: /usr/local/bin/python (found version \"3.6.9\") found components: Interpreter \n",
            "-- Found Torch: /usr/local/lib/python3.6/dist-packages/torch/include;/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include  \n",
            "-- The CUDA compiler identification is NVIDIA 10.1.243\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "-- Found CUDAToolkit: /usr/local/cuda/include (found version \"10.1.243\") \n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-build\n",
            "[1/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/math_util.cpp.o\n",
            "[2/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rng.cpp.o\n",
            "[3/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/dense_bit_line_maker.cpp.o\n",
            "[4/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_constantstep_device.cpp.o\n",
            "[5/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_difference_device.cpp.o\n",
            "[6/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu.cpp.o\n",
            "[7/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_expstep_device.cpp.o\n",
            "[8/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_forward_backward_pass.cpp.o\n",
            "[9/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_linearstep_device.cpp.o\n",
            "[10/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_pulsed.cpp.o\n",
            "[11/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_pulsed_device.cpp.o\n",
            "[12/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_pulsed_meta_parameter.cpp.o\n",
            "[13/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_simple_device.cpp.o\n",
            "[14/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_weight_updater.cpp.o\n",
            "[15/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_transfer_device.cpp.o\n",
            "[16/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/rpu_vector_device.cpp.o\n",
            "[17/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/sparse_bit_line_maker.cpp.o\n",
            "[18/57] Creating directories for 'cub'\n",
            "[19/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/weight_clipper.cpp.o\n",
            "[20/57] Building CXX object CMakeFiles/RPU_CPU.dir/src/rpucuda/weight_modifier.cpp.o\n",
            "[21/57] Linking CXX static library libRPU_CPU.a\n",
            "[22/57] Performing download step (download, verify and extract) for 'cub'\n",
            "-- Downloading...\n",
            "   dst='/content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-build/cub-prefix/src/1.8.0.zip'\n",
            "   timeout='none'\n",
            "-- Using src='https://github.com/NVlabs/cub/archive/1.8.0.zip'\n",
            "-- [download 100% complete]\n",
            "-- verifying file...\n",
            "       file='/content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-build/cub-prefix/src/1.8.0.zip'\n",
            "-- Downloading... done\n",
            "-- extracting...\n",
            "     src='/content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-build/cub-prefix/src/1.8.0.zip'\n",
            "     dst='/content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-build/cub-prefix/src/cub'\n",
            "-- extracting... [tar xfz]\n",
            "-- extracting... [analysis]\n",
            "-- extracting... [rename]\n",
            "-- extracting... [clean up]\n",
            "-- extracting... done\n",
            "[23/57] No update step for 'cub'\n",
            "[24/57] No patch step for 'cub'\n",
            "[25/57] No configure step for 'cub'\n",
            "[26/57] No build step for 'cub'\n",
            "[27/57] No install step for 'cub'\n",
            "[28/57] Completed 'cub'\n",
            "[29/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/cuda_math_util.cu.o\n",
            "[30/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/cuda_util.cu.o\n",
            "[31/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/io_manager.cu.o\n",
            "[32/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/noise_manager.cu.o\n",
            "[33/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/pulsed_weight_updater.cu.o\n",
            "[34/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/maximizer.cu.o\n",
            "[35/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda.cu.o\n",
            "[36/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_difference_device.cu.o\n",
            "[37/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/bit_line_maker.cu.o\n",
            "[38/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_expstep_device.cu.o\n",
            "[39/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_pulsed.cu.o\n",
            "[40/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_pulsed_device.cu.o\n",
            "[41/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_simple_device.cu.o\n",
            "[42/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_transfer_device.cu.o\n",
            "[43/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_linearstep_device.cu.o\n",
            "[44/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_vector_device.cu.o\n",
            "[45/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/update_management_helper.cu.o\n",
            "[46/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/test_helper.cu.o\n",
            "[47/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/rpucuda_constantstep_device.cu.o\n",
            "[48/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/weight_modifier_cuda.cu.o\n",
            "[49/57] Building CUDA object CMakeFiles/RPU_GPU.dir/src/rpucuda/cuda/weight_clipper_cuda.cu.o\n",
            "[50/57] Linking CXX static library CMakeFiles/RPU_GPU.dir/cmake_device_link.o\n",
            "[51/57] Linking CXX static library libRPU_GPU.a\n",
            "[52/57] Building CXX object src/aihwkit/simulator/CMakeFiles/rpu_base.dir/rpu_base_src/rpu_base.cpp.o\n",
            "[53/57] Building CXX object src/aihwkit/simulator/CMakeFiles/rpu_base.dir/rpu_base_src/rpu_base_devices.cpp.o\n",
            "[54/57] Building CXX object src/aihwkit/simulator/CMakeFiles/rpu_base.dir/rpu_base_src/rpu_base_tiles.cpp.o\n",
            "[55/57] Building CXX object src/aihwkit/simulator/CMakeFiles/rpu_base.dir/rpu_base_src/rpu_base_tiles_cuda.cpp.o\n",
            "[56/57] Linking CXX shared module src/aihwkit/simulator/rpu_base.cpython-36m-x86_64-linux-gnu.so\n",
            "[56/57] Install the project...\n",
            "-- Install configuration: \"Release\"\n",
            "-- Installing: /content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-install/src/aihwkit/simulator/rpu_base.cpython-36m-x86_64-linux-gnu.so\n",
            "-- Set runtime path of \"/content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-install/src/aihwkit/simulator/rpu_base.cpython-36m-x86_64-linux-gnu.so\" to \"$ORIGIN\"\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "-- Trying \"Ninja\" generator\n",
            "--------------------------------\n",
            "---------------------------\n",
            "----------------------\n",
            "-----------------\n",
            "------------\n",
            "-------\n",
            "--\n",
            "--\n",
            "-------\n",
            "------------\n",
            "-----------------\n",
            "----------------------\n",
            "---------------------------\n",
            "--------------------------------\n",
            "-- Trying \"Ninja\" generator - success\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Configuring Project\n",
            "  Working directory:\n",
            "    /content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-build\n",
            "  Command:\n",
            "    cmake /content/aihwkit_env/aihwkit -G Ninja -DCMAKE_INSTALL_PREFIX:PATH=/content/aihwkit_env/aihwkit/_skbuild/linux-x86_64-3.6/cmake-install -DPYTHON_EXECUTABLE:FILEPATH=/usr/bin/python3 -DPYTHON_VERSION_STRING:STRING=3.6.9 -DPYTHON_INCLUDE_DIR:PATH=/usr/include/python3.6m -DPYTHON_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpython3.6m.so -DSKBUILD:BOOL=TRUE -DCMAKE_MODULE_PATH:PATH=/usr/local/lib/python3.6/dist-packages/skbuild/resources/cmake -DUSE_CUDA=ON '-DRPU_CUDA_ARCHITECTURES=60;70' -DCMAKE_BUILD_TYPE:STRING=Release\n",
            "\n",
            "copying _skbuild/linux-x86_64-3.6/cmake-install/src/aihwkit/simulator/rpu_base.cpython-36m-x86_64-linux-gnu.so -> src/aihwkit/simulator/rpu_base.cpython-36m-x86_64-linux-gnu.so\n",
            "\n",
            "running build_ext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cftnglR9N5Sj"
      },
      "source": [
        "# Testing Complied Library Aihwkit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVZlWqI-L3cS",
        "outputId": "7218f071-0f9d-40de-e8f2-c6ac0a68ca6a"
      },
      "source": [
        "# Now testing if aihwkit was built/compiled correctly\n",
        "# This block is optional to run, it's to make sure the library compiled correctly\n",
        "# So in the future to run this compiled library from outside the python virtual env will have to set\n",
        "# the python path of where to look for modules before using aihwkit \n",
        "# so it tells the python to go look for our compiled module in this virtual env\n",
        "%%script bash\n",
        "cd aihwkit_env/aihwkit/\n",
        "pwd\n",
        "export PYTHONPATH=src/\n",
        "PYTHONPATH=src/ python examples/3_mnist_training.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/aihwkit_env/aihwkit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'examples/3_mnist_training.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z479FX64M301"
      },
      "source": [
        "# Testing Sample Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62FPCVtHbLgz",
        "outputId": "cf00c2bf-4321-42fb-d111-df5623f7786d"
      },
      "source": [
        "# Check device\n",
        "USE_CUDA = 0\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        " USE_CUDA = 1\n",
        " print(f\"Nvidia Cuda/GPU is available!\")\n",
        "else:\n",
        "  print (\"not available\") \n",
        " \n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        " print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nvidia Cuda/GPU is available!\n",
            "Sat Dec  5 03:02:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    23W / 300W |     10MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjmuBtTNMoOP",
        "outputId": "88d45d5b-68c6-4809-cab3-dd1d6e0c1bf9"
      },
      "source": [
        "# Writing the TestAihwkit.py file to /contents directory\n",
        "%%writefile TestAihwkit.py\n",
        "\n",
        "# All necessary imports\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/aihwkit_env/aihwkit/src/aihwkit/simulator\"\n",
        "from torch import Tensor\n",
        "from aihwkit.nn import AnalogLinear\n",
        "from aihwkit.optim import AnalogSGD\n",
        "from torch.nn.functional import mse_loss\n",
        "\n",
        "# Running some sample code \n",
        "x = Tensor([[0.1, 0.2, 0.4, 0.3], [0.2, 0.1, 0.1, 0.3]])\n",
        "y = Tensor([[1.0, 0.5], [0.7, 0.3]])\n",
        "\n",
        "model = AnalogLinear(4, 2)\n",
        "optimizer = AnalogSGD(model.parameters(), lr=0.1)\n",
        "optimizer.regroup_param_groups(model)\n",
        "\n",
        "for epoch in range(10):\n",
        "    pred = model(x)\n",
        "    loss = mse_loss(pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(\"Loss error: \" + str(loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing TestAihwkit.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL68cZhOVK33",
        "outputId": "f01a6512-6d20-487e-c960-9d10ee822d11"
      },
      "source": [
        "# Now trying to run the test code from outside the aihwkit virtual environment\n",
        "# Note: the python module search path has already been added in the cell above \n",
        "# This should work....\n",
        "%%script bash\n",
        "python TestAihwkit.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss error: tensor(0.6305, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.4623, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.4167, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.2799, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.2992, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.2023, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.2241, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.1648, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.1718, grad_fn=<MseLossBackward>)\n",
            "Loss error: tensor(0.1095, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7nZNSq0bFbk"
      },
      "source": [
        "# Modified MNIST 4 Layer FCNN From Aihwkit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Vzco0HbNhC"
      },
      "source": [
        "# Writing the below python code into FCNN_3_Layer_MNIST.py so \n",
        "# we can invoke/run this python code from bash environment afterwards\n",
        "# Note: we can now set the \"cuda\" flags here to true so we can use GPU support\n",
        "%%writefile FCNN_3_Layer_MNIST.py\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# (C) Copyright 2020 IBM. All Rights Reserved.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"aihwkit example 3: MNIST training.\n",
        "\n",
        "MNIST training example based on the paper:\n",
        "https://www.frontiersin.org/articles/10.3389/fnins.2016.00333/full\n",
        "\n",
        "Uses learning rates of  = 0.01, 0.005, and 0.0025\n",
        "for epochs 010, 1120, and 2130, respectively.\n",
        "\"\"\"\n",
        "\n",
        "# Importing time\n",
        "from time import time\n",
        "\n",
        "# Setting the correct python path\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/aihwkit_env/aihwkit/src/aihwkit/simulator\"\n",
        "\n",
        "# Imports from PyTorch.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Imports from aihwkit.\n",
        "from aihwkit.nn import AnalogLinear\n",
        "from aihwkit.optim import AnalogSGD\n",
        "from aihwkit.simulator.configs import SingleRPUConfig\n",
        "from aihwkit.simulator.configs.devices import ConstantStepDevice\n",
        "from aihwkit.simulator.configs.devices import ExpStepDevice\n",
        "from aihwkit.simulator.configs.utils import (WeightNoiseType, WeightClipType, WeightModifierType)\n",
        "\n",
        "\n",
        "# Path where the datasets will be stored.\n",
        "TRAIN_DATASET = 'data/TRAIN_DATASET'\n",
        "TEST_DATASET = 'data/TEST_DATASET'\n",
        "\n",
        "# Network definition.\n",
        "INPUT_SIZE = 784\n",
        "HIDDEN_SIZES = [256, 128]\n",
        "OUTPUT_SIZE = 10\n",
        "\n",
        "# Training parameters.\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Create RPU configuration with noise\n",
        "# Noise of the weight computations\n",
        "rpu_config=SingleRPUConfig(device=ExpStepDevice())\n",
        "rpu_config.forward.w_noise_type=WeightNoiseType.ADDITIVE_CONSTANT\n",
        "rpu_config.forward.w_noise = 0.02\n",
        "rpu_config.backward.w_noise_type=WeightNoiseType.ADDITIVE_CONSTANT\n",
        "rpu_config.backward.w_noise = 0.02\n",
        "\n",
        "\n",
        "\n",
        "def load_images():\n",
        "    \"\"\"Load images for train from the torchvision datasets.\"\"\"\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    # Load the images.\n",
        "    train_set = datasets.MNIST(TRAIN_DATASET,\n",
        "                               download=True, train=True, transform=transform)\n",
        "    val_set = datasets.MNIST(TEST_DATASET,\n",
        "                             download=True, train=False, transform=transform)\n",
        "    train_data = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    validation_data = torch.utils.data.DataLoader(\n",
        "        val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    return train_data, validation_data\n",
        "\n",
        "\n",
        "def create_analog_network(input_size, hidden_sizes, output_size):\n",
        "    \"\"\"Create the neural network using analog and digital layers.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): size of the Tensor at the input.\n",
        "        hidden_sizes (list): list of sizes of the hidden layers (2 layers).\n",
        "        output_size (int): size of the Tensor at the output.\n",
        "    \"\"\"\n",
        "    # Include RPU configuration model\n",
        "    model = nn.Sequential(\n",
        "        AnalogLinear(input_size, hidden_sizes[0], True, rpu_config),\n",
        "        nn.Sigmoid(),\n",
        "        AnalogLinear(hidden_sizes[0], hidden_sizes[1], True, rpu_config),\n",
        "        nn.Sigmoid(),\n",
        "        AnalogLinear(hidden_sizes[1], output_size, True, rpu_config),\n",
        "        nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "    print(model)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_sgd_optimizer(model):\n",
        "    \"\"\"Create the analog-aware optimizer.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): model to be trained.\n",
        "    \"\"\"\n",
        "    optimizer = AnalogSGD(model.parameters(), lr=0.05)\n",
        "    optimizer.regroup_param_groups(model)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def train(model, train_set):\n",
        "    \"\"\"Train the network.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): model to be trained.\n",
        "        train_set (DataLoader): dataset of elements to use as input for training.\n",
        "    \"\"\"\n",
        "    classifier = nn.NLLLoss()\n",
        "    optimizer = create_sgd_optimizer(model)\n",
        "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    time_init = time()\n",
        "    for epoch_number in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        for images, labels in train_set:\n",
        "            # Flatten MNIST images into a 784 vector.\n",
        "            images = images.view(images.shape[0], -1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # Add training Tensor to the model (input).\n",
        "            output = model(images)\n",
        "            loss = classifier(output, labels)\n",
        "\n",
        "            # Run training (backward propagation).\n",
        "            loss.backward()\n",
        "\n",
        "            # Optimize weights.\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print('Epoch {} - Training loss: {:.16f}'.format(\n",
        "            epoch_number, total_loss / len(train_set)))\n",
        "\n",
        "        # Decay learning rate if needed.\n",
        "        scheduler.step()\n",
        "\n",
        "    print('\\nTraining Time (s) = {}'.format(time()-time_init))\n",
        "\n",
        "\n",
        "def test_evaluation(model, val_set):\n",
        "    \"\"\"Test trained network\n",
        "\n",
        "    Args:\n",
        "        model (nn.Model): Trained model to be evaluated\n",
        "        val_set (DataLoader): Validation set to perform the evaluation\n",
        "    \"\"\"\n",
        "    # Setup counter of images predicted to 0.\n",
        "    predicted_ok = 0\n",
        "    total_images = 0\n",
        "\n",
        "    for images, labels in val_set:\n",
        "        # Predict image.\n",
        "        for i in range(len(labels)):\n",
        "            image = images[i].view(1, INPUT_SIZE)\n",
        "            with torch.no_grad():\n",
        "                pred = model(image)\n",
        "\n",
        "        probabilities_tensor = torch.exp(pred)\n",
        "        probabilities = list(probabilities_tensor.numpy()[0])\n",
        "\n",
        "        # Get labels.\n",
        "        predicted_label = probabilities.index(max(probabilities))\n",
        "        validation_label = labels.numpy()[-1]\n",
        "\n",
        "        # Check if predicted image match with validation label.\n",
        "        if validation_label == predicted_label:\n",
        "            predicted_ok += 1\n",
        "        total_images += 1\n",
        "\n",
        "    print('\\nNumber Of Images Tested = {}'.format(total_images))\n",
        "    print('Model Accuracy = {}'.format(predicted_ok/total_images))\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Train a PyTorch analog model with the MNIST dataset.\"\"\"\n",
        "    # Load datasets.\n",
        "    train_dataset, validation_dataset = load_images()\n",
        "\n",
        "    # Prepare the model.\n",
        "    model = create_analog_network(INPUT_SIZE, HIDDEN_SIZES, OUTPUT_SIZE)\n",
        "\n",
        "    # Train the model.\n",
        "    train(model, train_dataset)\n",
        "\n",
        "    # Evaluate the trained model.\n",
        "    test_evaluation(model, validation_dataset)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Execute only if run as the entry point into the program.\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gqbcxczdwTh"
      },
      "source": [
        "# Running the above code\n",
        "%%script bas\n",
        "python FCNN_3_Layer_MNIST.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yNDYQEgeQ-Z"
      },
      "source": [
        "# Modified CNN Lenet5 from Aihwkit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yuFjEWSe5Dx"
      },
      "source": [
        "%%writefile CNN_Lenet5_MNIST.py\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "# (C) Copyright 2020 IBM. All Rights Reserved.\n",
        "\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"aihwkit example 4: analog CNN.\n",
        "\n",
        "Mnist dataset on a LeNet5 inspired network based on the paper:\n",
        "https://www.frontiersin.org/articles/10.3389/fnins.2017.00538/full\n",
        "\n",
        "Learning rates of  = 0.01 for all the epochs with minibatch 8.\n",
        "\"\"\"\n",
        "\n",
        "# Set the python path to search for the compiled version of aihwkit module\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/aihwkit_env/aihwkit/src/aihwkit/simulator\"\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Imports from numpy and matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Imports from PyTorch.\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Imports from aihwkit.\n",
        "from aihwkit.nn import AnalogConv2d, AnalogLinear, AnalogSequential\n",
        "from aihwkit.optim import AnalogSGD\n",
        "from aihwkit.simulator.configs import SingleRPUConfig, FloatingPointRPUConfig\n",
        "from aihwkit.simulator.configs.devices import ConstantStepDevice, FloatingPointDevice\n",
        "\n",
        "\n",
        "# Check device\n",
        "USE_CUDA = 0\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"Cuda is available! GPU Support activated!\")\n",
        "  USE_CUDA = 1\n",
        "\n",
        "# Path to store datasets\n",
        "TRAIN_DATASET = os.path.join('data', 'TRAIN_DATASET')\n",
        "TEST_DATASET = os.path.join('data', 'TEST_DATASET')\n",
        "\n",
        "# Path to store results\n",
        "RESULTS = os.path.join('results', 'LENET5')\n",
        "\n",
        "# Training parameters\n",
        "SEED = 1\n",
        "N_EPOCHS = 30\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 0.01\n",
        "N_CLASSES = 10\n",
        "\n",
        "# Select the device model to use in the training.\n",
        "# * If `SingleRPUConfig(device=ConstantStepDevice())` then analog tiles with\n",
        "#   constant step devices will be used,\n",
        "# * If `FloatingPointRPUConfig(device=FloatingPointDevice())` then standard\n",
        "#   floating point devices will be used\n",
        "RPU_CONFIG = SingleRPUConfig(device=ConstantStepDevice())\n",
        "# RPU_CONFIG = FloatingPointRPUConfig(device=FloatingPointDevice())\n",
        "\n",
        "\n",
        "def load_images():\n",
        "    \"\"\"Load images for train from torchvision datasets.\"\"\"\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train_set = datasets.MNIST(TRAIN_DATASET, download=True, train=True, transform=transform)\n",
        "    val_set = datasets.MNIST(TEST_DATASET, download=True, train=False, transform=transform)\n",
        "    train_data = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    validation_data = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_data, validation_data\n",
        "\n",
        "\n",
        "class LeNet5(AnalogSequential):\n",
        "    \"\"\"LeNet5 inspired analog model.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            AnalogConv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1,\n",
        "                         rpu_config=RPU_CONFIG),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            AnalogConv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1,\n",
        "                         rpu_config=RPU_CONFIG),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            AnalogLinear(in_features=512, out_features=128, rpu_config=RPU_CONFIG),\n",
        "            nn.Tanh(),\n",
        "            AnalogLinear(in_features=128, out_features=N_CLASSES, rpu_config=RPU_CONFIG),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        return probs\n",
        "\n",
        "\n",
        "def create_sgd_optimizer(model, learning_rate):\n",
        "    \"\"\"Create the analog-aware optimizer.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): model to be trained\n",
        "        learning_rate (float): global parameter to define learning rate\n",
        "    \"\"\"\n",
        "    optimizer = AnalogSGD(model.parameters(), lr=learning_rate)\n",
        "    optimizer.regroup_param_groups(model)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def train_step(train_data, model, criterion, optimizer):\n",
        "    \"\"\"Train network.\n",
        "\n",
        "    Args:\n",
        "        train_data (DataLoader): Validation set to perform the evaluation\n",
        "        model (nn.Module): Trained model to be evaluated\n",
        "        criterion (nn.CrossEntropyLoss): criterion to compute loss\n",
        "        optimizer (Optimizer): analog model optimizer\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for images, labels in train_data:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Add training Tensor to the model (input).\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # Run training (backward propagation).\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimize weights.\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = total_loss / len(train_data.dataset)\n",
        "\n",
        "    return model, optimizer, epoch_loss\n",
        "\n",
        "\n",
        "def test_evaluation(validation_data, model, criterion):\n",
        "    \"\"\"Test trained network\n",
        "\n",
        "    Args:\n",
        "        validation_data (DataLoader): Validation set to perform the evaluation\n",
        "        model (nn.Module): Trained model to be evaluated\n",
        "        criterion (nn.CrossEntropyLoss): criterion to compute loss\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    predicted_ok = 0\n",
        "    total_images = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for images, labels in validation_data:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, labels)\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, predicted = torch.max(pred.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        predicted_ok += (predicted == labels).sum().item()\n",
        "        accuracy = predicted_ok/total_images*100\n",
        "        error = (1-predicted_ok/total_images)*100\n",
        "\n",
        "    epoch_loss = total_loss / len(validation_data.dataset)\n",
        "    print (len(validation_data.dataset))\n",
        "\n",
        "    return model, epoch_loss, error, accuracy\n",
        "\n",
        "\n",
        "def training_loop(model, criterion, optimizer, train_data, validation_data, epochs, print_every=1):\n",
        "    \"\"\"Training loop.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained model to be evaluated\n",
        "        criterion (nn.CrossEntropyLoss): criterion to compute loss\n",
        "        optimizer (Optimizer): analog model optimizer\n",
        "        train_data (DataLoader): Validation set to perform the evaluation\n",
        "        validation_data (DataLoader): Validation set to perform the evaluation\n",
        "        epochs (int): global parameter to define epochs number\n",
        "        print_every (int): defines how many times to print training progress\n",
        "    \"\"\"\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    test_error = []\n",
        "\n",
        "    # Train model\n",
        "    for epoch in range(0, epochs):\n",
        "        # Train_step\n",
        "        model, optimizer, train_loss = train_step(train_data, model, criterion, optimizer)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validate_step\n",
        "        with torch.no_grad():\n",
        "            model, valid_loss, error, accuracy = test_evaluation(\n",
        "                validation_data, model, criterion)\n",
        "            valid_losses.append(valid_loss)\n",
        "            test_error.append(error)\n",
        "\n",
        "        if epoch % print_every == (print_every - 1):\n",
        "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
        "                  f'Epoch: {epoch}\\t'\n",
        "                  f'Train loss: {train_loss:.4f}\\t'\n",
        "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
        "                  f'Test error: {error:.2f}%\\t'\n",
        "                  f'Accuracy: {accuracy:.2f}%\\t')\n",
        "\n",
        "    # Save results and plot figures\n",
        "    np.savetxt(os.path.join(RESULTS, \"Test_error.csv\"), test_error, delimiter=\",\")\n",
        "    np.savetxt(os.path.join(RESULTS, \"Train_Losses.csv\"), train_losses, delimiter=\",\")\n",
        "    np.savetxt(os.path.join(RESULTS, \"Valid_Losses.csv\"), valid_losses, delimiter=\",\")\n",
        "    plot_results(train_losses, valid_losses, test_error)\n",
        "\n",
        "    return model, optimizer, (train_losses, valid_losses, test_error)\n",
        "\n",
        "\n",
        "def plot_results(train_losses, valid_losses, test_error):\n",
        "    \"\"\"Plot results.\n",
        "\n",
        "    Args:\n",
        "        train_losses: training losses as calculated in the training_loop\n",
        "        valid_losses: validation losses as calculated in the training_loop\n",
        "        test_error: test error as calculated in the training_loop\n",
        "    \"\"\"\n",
        "    fig = plt.plot(train_losses, 'r-s', valid_losses, 'b-o')\n",
        "    plt.title('aihwkit LeNet5')\n",
        "    plt.legend(fig[:2], ['Training Losses', 'Validation Losses'])\n",
        "    plt.xlabel('Epoch number')\n",
        "    plt.ylabel('Loss [A.U.]')\n",
        "    plt.grid(which='both', linestyle='--')\n",
        "    plt.savefig(os.path.join(RESULTS, 'test_losses.png'))\n",
        "    plt.close()\n",
        "\n",
        "    fig = plt.plot(test_error, 'r-s')\n",
        "    plt.title('aihwkit LeNet5')\n",
        "    plt.legend(fig[:1], ['Validation Accuracy'])\n",
        "    plt.xlabel('Epoch number')\n",
        "    plt.ylabel('Test Error [%]')\n",
        "    plt.yscale('log')\n",
        "    plt.ylim((5e-1, 1e2))\n",
        "    plt.grid(which='both', linestyle='--')\n",
        "    plt.savefig(os.path.join(RESULTS, 'test_error.png'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Start time of lenet5\n",
        "    start_time = time()\n",
        "\n",
        "    \"\"\"Train a PyTorch CNN analog model with the MNIST dataset.\"\"\"\n",
        "    # Make sure the directory where to save the results exist.\n",
        "    # Results include: Loss vs Epoch graph, Accuracy vs Epoch graph and vector data.\n",
        "    os.makedirs(RESULTS, exist_ok=True)\n",
        "    torch.manual_seed(SEED)\n",
        "\n",
        "    # Load datasets.\n",
        "    train_data, validation_data = load_images()\n",
        "\n",
        "    # Prepare the model.\n",
        "    model = LeNet5()\n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "    print(model)\n",
        "\n",
        "    print(f'\\n{datetime.now().time().replace(microsecond=0)} --- '\n",
        "          f'Started LeNet5 Example')\n",
        "\n",
        "    optimizer = create_sgd_optimizer(model, LEARNING_RATE)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model, optimizer, _ = training_loop(model, criterion, optimizer, train_data, validation_data,\n",
        "                                        N_EPOCHS)\n",
        "\n",
        "    # End time of lenet5\n",
        "    print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
        "          f'Completed LeNet5 Example')\n",
        "    end_time = time()\n",
        "    print(f'CNN Lenet5 took: {(end_time - start_time)/60} (mins) or {(end_time - start_time)} (s)')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Execute only if run as the entry point into the program\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV3w7Tjigb0s"
      },
      "source": [
        "# Running the code above\n",
        "# if aihwkit has not been compiled with cuda support need to rebuild the library \n",
        "# with cuda support \n",
        "%%script bash\n",
        "python CNN_Lenet5_MNIST.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLnWyK0djEGn"
      },
      "source": [
        "# Comparing accuracies of different fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gLuak61jGKs"
      },
      "source": [
        "%%writefile multi_layer_investigation_jack.py\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# (C) Copyright 2020 IBM. All Rights Reserved.\n",
        "#\n",
        "# This code is licensed under the Apache License, Version 2.0. You may\n",
        "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
        "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
        "#\n",
        "# Any modifications or derivative works of this code must retain this\n",
        "# copyright notice, and modified files need to carry a notice indicating\n",
        "# that they have been altered from the originals.\n",
        "\n",
        "\"\"\"\n",
        "aihwkit example 3: MNIST training.\n",
        "\n",
        "MNIST training example based on the paper:\n",
        "https://www.frontiersin.org/articles/10.3389/fnins.2016.00333/full\n",
        "\n",
        "Uses learning rates of  = 0.01, 0.005, and 0.0025\n",
        "for epochs 010, 1120, and 2130, respectively.\n",
        "\n",
        "\"\"\"\n",
        "# setting python path\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/aihwkit_env/aihwkit/src/aihwkit/simulator\"\n",
        "\n",
        "# imports from numpy and matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# default dict and pickle\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "# Importing time module\n",
        "from time import time\n",
        "\n",
        "# Imports from PyTorch.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Imports from aihwkit.\n",
        "import aihwkit.optim as optim\n",
        "from aihwkit.nn import AnalogLinear\n",
        "from aihwkit.optim import AnalogSGD\n",
        "from aihwkit.simulator.configs import SingleRPUConfig\n",
        "from aihwkit.simulator.configs.devices import ConstantStepDevice\n",
        "from aihwkit.simulator.configs.devices import ExpStepDevice\n",
        "from aihwkit.simulator.configs.utils import (WeightNoiseType, WeightClipType, WeightModifierType)\n",
        "\n",
        "# Path where the datasets will be stored.\n",
        "TRAIN_DATASET = 'MyData/TRAIN_DATASET'\n",
        "TEST_DATASET = 'MyData/TEST_DATASET'\n",
        "\n",
        "# Network definition.\n",
        "INPUT_SIZE = 784\n",
        "OUTPUT_SIZE = 10\n",
        "ANALOG_LINEAR_CONFIG = {\n",
        "    \"4_Layer\": [512, 256, 128, 10],\n",
        "    \"3_Layer\": [256, 128, 10],\n",
        "    \"2_Layer\": [128, 10]\n",
        "}\n",
        "\n",
        "# Activation functions\n",
        "activation_func = {\n",
        "    'Relu': nn.ReLU(),  # defacto standard in deep learning these days\n",
        "    'Sig': nn.Sigmoid(),  # may provide vanishing gradient problems in deep NNs\n",
        "    'Tanh': nn.Tanh(),  # may provide vanishing gradient problems in deep NNs\n",
        "    'LeakyRelu': nn.LeakyReLU(),  # slightly better than ReLU as it solves the problem of \"dead neurons\" in the network\n",
        "    'ELU': nn.ELU(),\n",
        "}\n",
        "\n",
        "# Training parameters.\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "lr = 0.05\n",
        "\n",
        "# RPU configurations\n",
        "rpu_config = SingleRPUConfig(device=ExpStepDevice())\n",
        "rpu_config.forward.w_noise_type = WeightNoiseType.ADDITIVE_CONSTANT\n",
        "rpu_config.forward.w_noise = 0.02\n",
        "rpu_config.backward.w_noise_type = WeightNoiseType.ADDITIVE_CONSTANT\n",
        "rpu_config.backward.w_noise = 0.02\n",
        "\n",
        "\n",
        "# for applying preprocessing and loading of images\n",
        "def preprocessLoadImages():\n",
        "    # load images and  do preprocessing from the MNIST dataset using torchvision dataset class\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    # create torchvision training and validation data sets\n",
        "    train_set = datasets.MNIST(TRAIN_DATASET, download=True, train=True, transform=transform)\n",
        "    val_set = datasets.MNIST(TEST_DATASET, download=True, train=False, transform=transform)\n",
        "\n",
        "    # create torchvision data loaders for training and validation sets\n",
        "    train_data = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=6, pin_memory=True)\n",
        "    validation_data = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=6, pin_memory=True)\n",
        "\n",
        "    return train_data, validation_data\n",
        "\n",
        "\n",
        "# create our analog fully connected network class template\n",
        "class FullyConnectedAnalogLinear(nn.Module):\n",
        "\n",
        "    # constructor\n",
        "    def __init__(self, input_size, output_size, analog_layers_config, rpu_config, activation_func):\n",
        "        super(FullyConnectedAnalogLinear, self).__init__()\n",
        "\n",
        "        # define input and output size holders\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # define fully connected layers\n",
        "        self.fully_connected_layers = self._create_fully_connected_layers(self,\n",
        "                                                                          analog_layers_config=analog_layers_config,\n",
        "                                                                          rpu_config=rpu_config,\n",
        "                                                                          activation_func=activation_func)\n",
        "\n",
        "    # function to create fully connected layers dynamically for us\n",
        "    @staticmethod\n",
        "    def _create_fully_connected_layers(self, analog_layers_config, rpu_config, activation_func):\n",
        "\n",
        "        # input and output sizes\n",
        "        input_size = self.input_size\n",
        "        output_size = self.output_size\n",
        "\n",
        "        # temp list to hold our layer definitions\n",
        "        layers = []\n",
        "\n",
        "        # looping through our analog linear layers config\n",
        "        for x in analog_layers_config:\n",
        "            if (x != output_size):\n",
        "                out_channel = x\n",
        "                layers += [AnalogLinear(in_features=input_size,\n",
        "                                        out_features=out_channel,\n",
        "                                        bias=True, rpu_config=rpu_config),\n",
        "                           activation_func]\n",
        "                input_size = x\n",
        "            else:\n",
        "                out_channel = x\n",
        "                layers += [AnalogLinear(in_features=input_size,\n",
        "                                        out_features=output_size,\n",
        "                                        bias=True, rpu_config=rpu_config)]\n",
        "                input_size = x\n",
        "\n",
        "        # return a network block containing all my layers stacked together sequentially\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    # defines how our analog linear network is connected -> this is the forward pass function\n",
        "    def forward(self, x):\n",
        "        # flatten MNIST images into a 784 vector in the image dimension while keeping batch size the same.\n",
        "        # essentially will have a tensor of shape: (Batch_size, linear image vector -> 784)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fully_connected_layers(x)\n",
        "        m = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        return m(x)\n",
        "\n",
        "\n",
        "# function to create our optimizer for stochastic gradient descent\n",
        "def create_sgd_optimizer(model, lr):\n",
        "    \"\"\"Args: model (nn.Module): model to be trained.\n",
        "    \"\"\"\n",
        "    optimizer = AnalogSGD(model.parameters(), lr=lr)\n",
        "    optimizer.regroup_param_groups(model)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "# training function\n",
        "def train(model, train_set, lr):\n",
        "    \"\"\"Train the network.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): model to be trained.\n",
        "        train_set (DataLoader): dataset of elements to use as input for training.\n",
        "    \"\"\"\n",
        "    loss_function = nn.NLLLoss()\n",
        "    optimizer = create_sgd_optimizer(model, lr)\n",
        "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "    model.train()\n",
        "    time_init = time()\n",
        "    for epoch_number in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        for images, labels in train_set:\n",
        "            # 0 the gradients per batch so theres no gradient mixing between batches\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward pass\n",
        "            output = model(images)\n",
        "\n",
        "            # find loss\n",
        "            loss = loss_function(output, labels)\n",
        "\n",
        "            # Run training (backward propagation).\n",
        "            loss.backward()\n",
        "\n",
        "            # Optimize weights.\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print('Epoch {} - Training loss: {:.16f}'.format(\n",
        "            epoch_number, total_loss / len(train_set)))\n",
        "\n",
        "        # Decay learning rate if needed.\n",
        "        scheduler.step()\n",
        "\n",
        "    print('\\nTraining Time (s) = {}'.format(time() - time_init))\n",
        "    total_time = time() - time_init\n",
        "    return total_time\n",
        "\n",
        "\n",
        "# predict on validation set\n",
        "def test_evaluation(model, val_set):\n",
        "    \"\"\"Test trained network\n",
        "\n",
        "    Args:\n",
        "        model (nn.Model): Trained model to be evaluated\n",
        "        val_set (DataLoader): Validation set to perform the evaluation\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # Setup counter of images predicted to 0.\n",
        "    predicted_ok = 0\n",
        "    total_images = 0\n",
        "\n",
        "    for images, labels in val_set:\n",
        "        # Predict image.\n",
        "        for i in range(len(labels)):\n",
        "            image = images[i]\n",
        "            with torch.no_grad():\n",
        "                pred = model(image)\n",
        "\n",
        "        probabilities_tensor = torch.exp(pred)\n",
        "        probabilities = list(probabilities_tensor.numpy()[0])\n",
        "\n",
        "        # Get labels.\n",
        "        predicted_label = probabilities.index(max(probabilities))\n",
        "        validation_label = labels.numpy()[-1]\n",
        "\n",
        "        # Check if predicted image match with validation label.\n",
        "        if validation_label == predicted_label:\n",
        "            predicted_ok += 1\n",
        "        total_images += 1\n",
        "\n",
        "    print('\\nNumber Of Images Tested = {}'.format(total_images))\n",
        "    print('Model Accuracy = {}'.format(predicted_ok / total_images))\n",
        "    accuracy = predicted_ok / total_images\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# where our network starts processing\n",
        "def train_eval(layer_key):\n",
        "    print(f\"STARTING ANALOG LINEAR TRAINING FOR: {layer_key}\")\n",
        "    \"\"\"Train a PyTorch analog model with the MNIST dataset.\"\"\"\n",
        "    # Load datasets.\n",
        "    train_dataset, validation_dataset = preprocessLoadImages()\n",
        "    # Prepare the model.\n",
        "    model = FullyConnectedAnalogLinear(input_size=INPUT_SIZE, output_size=OUTPUT_SIZE,\n",
        "                                       analog_layers_config=ANALOG_LINEAR_CONFIG[str(layer_key)],\n",
        "                                       rpu_config=rpu_config, activation_func=activation_func['Relu'])\n",
        "    print(f\"My model: \\n{model}\")\n",
        "    # Train the model.\n",
        "    total_time = train(model, train_dataset, lr=lr)\n",
        "    # Evaluate the trained model.\n",
        "    acc = test_evaluation(model, validation_dataset)\n",
        "    # returns the total accuracy and total time for this experiment\n",
        "    return acc, total_time\n",
        "\n",
        "# graph my results\n",
        "def graph_results(path):\n",
        "\n",
        "    # load pickle file back into program\n",
        "    with open(str(path), 'rb') as file:\n",
        "        results = pickle.load(file)\n",
        "\n",
        "    # graph our results\n",
        "    layer_configs = list(results.keys())\n",
        "    layer_configs = layer_configs[::-1]\n",
        "    bar1 = np.arange(len(layer_configs))\n",
        "    bar2 = [i + 0.4 for i in bar1]\n",
        "\n",
        "    accuracies = list(results.values())\n",
        "    accuracies = accuracies[::-1]\n",
        "    acc_list = []\n",
        "    time_list = []\n",
        "    for acc, run_time in accuracies:\n",
        "        acc_list.append(acc*100)\n",
        "        time_list.append(run_time)\n",
        "\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.bar(bar1, acc_list, color='g', width=0.4, label=\"Accuracies (%)\")\n",
        "    plt.bar(bar2, run_time, color='b', width=0.4, label=\"Run time (s)\")\n",
        "    plt.xticks(bar1+0.2, layer_configs)\n",
        "    plt.ylim(92,100)\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Analogy Fully Connected Layer Configurations\")\n",
        "    plt.ylabel(\"Validation Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Create a dictionary to hold our simulation results\n",
        "    results = defaultdict(float)\n",
        "\n",
        "    # Execute only if run as the entry point into the program.\n",
        "    for layer_key in ANALOG_LINEAR_CONFIG.keys():\n",
        "        accuracy, total_time = train_eval(layer_key)\n",
        "        results[str(layer_key)] = (accuracy, total_time)\n",
        "\n",
        "    print(f\"SAVING RESULTS NOW! \\n{results}\")\n",
        "    # Saving results\n",
        "    with open('./results.pickle', 'wb') as MyDict:\n",
        "        pickle.dump(results, MyDict, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    # graph_results(\"./results.pickle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqpm_7GekDSX"
      },
      "source": [
        "# To run the code above, make sure to enable GPU first\n",
        "%%script bash\n",
        "python multi_layer_investigation_jack.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJPH8mGYfL7i"
      },
      "source": [
        "# GUI\n",
        "under construction.......\n",
        "\n",
        "Check reference: https://github.com/salvacorts/Keras-MNIST-Paint\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDcTkgnzfaAg"
      },
      "source": [
        "# LOAD\n",
        "from PIL import ImageFilter\n",
        "from PIL import Image\n",
        "\n",
        "def imageprepare(argv):\n",
        "    im = Image.open(argv).convert('L')\n",
        "    width = float(im.size[0])\n",
        "    height = float(im.size[1])\n",
        "    newImage = Image.new('L', (28, 28), (255))  # creates white canvas of 28x28 pixels\n",
        "\n",
        "    if width > height:  # check which dimension is bigger\n",
        "        # Width is bigger. Width becomes 20 pixels.\n",
        "        nheight = int(round((20.0 / width * height), 0))  # resize height according to ratio width\n",
        "        if (nheight == 0):  # rare case but minimum is 1 pixel\n",
        "            nheight = 1\n",
        "            # resize and sharpen\n",
        "        img = im.resize((20, nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
        "        wtop = int(round(((28 - nheight) / 2), 0))  # calculate horizontal position\n",
        "        newImage.paste(img, (4, wtop))  # paste resized image on white canvas\n",
        "    else:\n",
        "        # Height is bigger. Heigth becomes 20 pixels.\n",
        "        nwidth = int(round((20.0 / height * width), 0))  # resize width according to ratio height\n",
        "        if (nwidth == 0):  # rare case but minimum is 1 pixel\n",
        "            nwidth = 1\n",
        "            # resize and sharpen\n",
        "        img = im.resize((nwidth, 20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
        "        wleft = int(round(((28 - nwidth) / 2), 0))  # caculate vertical pozition\n",
        "        newImage.paste(img, (wleft, 4))  # paste resized image on white canvas\n",
        "\n",
        "    # newImage.save(\"sample.png\n",
        "\n",
        "    tv = list(newImage.getdata())  # get pixel values\n",
        "\n",
        "    # normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n",
        "    tva = [(255 - x) * 1.0 / 255.0 for x in tv]\n",
        "    return tva\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import image as pltImage\n",
        "import numpy as np\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        with open(\"models/model.json\") as json_model:\n",
        "            self.model = model_from_json(json_model.read())\n",
        "            json_model.close()\n",
        "\n",
        "        self.model.load_weights(\"models/model.weights\")\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    def Predict(self, image):\n",
        "        array = [imageprepare(image)]\n",
        "        imageArray = [[0 for d in range(28)] for y in range(28)]\n",
        "        k = 0\n",
        "        for i in range(28):\n",
        "            for j in range(28):\n",
        "                imageArray[i][j] = array[0][k]\n",
        "                k = k + 1\n",
        "\n",
        "        imageArray = np.array(imageArray)\n",
        "        imageArray = imageArray.reshape(1, 28, 28, 1)\n",
        "\n",
        "        pltImage.imsave(\"images/current.png\", imageArray.reshape(28,28))\n",
        "\n",
        "        scores = self.model.predict(np.array(imageArray))\n",
        "\n",
        "        number = 0\n",
        "        bestScore = -1\n",
        "        prediction = -1\n",
        "        for score in scores[0]:\n",
        "            if score > bestScore:\n",
        "                bestScore = score\n",
        "                prediction = number\n",
        "\n",
        "            number += 1\n",
        "\n",
        "        return prediction, scores[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNDBsVXjfLHP"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from tkinter import *\n",
        "from PIL import Image, ImageTk\n",
        "from threading import Thread\n",
        "import webbrowser\n",
        "\n",
        "drawing_size = 280\n",
        "\n",
        "\n",
        "class Paint(object):\n",
        "\n",
        "    DEFAULT_PEN_SIZE = 8.0\n",
        "    DEFAULT_COLOR = \"white\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.root = Tk()\n",
        "        self.root.title(\"ECSE 541 MINST Predictor\")\n",
        "        self.root.resizable(0, 0)\n",
        "\n",
        "        self.model = Model()\n",
        "\n",
        "        self.brush_button = Button(self.root, text=\"Predict\", command=self.Predict)\n",
        "        self.brush_button.grid(row=0, column=2)\n",
        "\n",
        "        self.eraser_button = Button(self.root, text=\"Clear\", command=self.use_eraser)\n",
        "        self.eraser_button.grid(row=0, column=3)\n",
        "\n",
        "        self.c = Canvas(self.root, bg=\"black\", width=drawing_size, height=drawing_size)\n",
        "        self.c.grid(row=1, columnspan=5)\n",
        "        # self.c.grid(row=1, sticky = W, columnspan = 2)\n",
        "\n",
        "        # prediction label\n",
        "        self.predictionLabel = Text(\n",
        "            self.root,\n",
        "            fg=\"blue\",\n",
        "            height=1,\n",
        "            width=30,\n",
        "            borderwidth=0,\n",
        "            highlightthickness=0,\n",
        "            relief=\"ridge\",\n",
        "        )\n",
        "        self.predictionLabel.grid(row=0, column=6)\n",
        "\n",
        "        # prediction score\n",
        "        self.predictionScores = Text(\n",
        "            self.root,\n",
        "            fg=\"black\",\n",
        "            height=10,\n",
        "            width=30,\n",
        "            padx=10,\n",
        "            borderwidth=0,\n",
        "            highlightthickness=0,\n",
        "            relief=\"ridge\",\n",
        "        )\n",
        "        self.predictionScores.grid(row=1, column=6)\n",
        "\n",
        "        # self.image = Canvas(\n",
        "        #     self.root,\n",
        "        #     width=drawing_size,\n",
        "        #     height=drawing_size,\n",
        "        #     highlightthickness=0,\n",
        "        #     relief=\"ridge\",\n",
        "        # )\n",
        "        # self.image.create_image(0, 0, anchor=NW, tags=\"IMG\")\n",
        "        # self.image.grid(row=2, rowspan=5, columnspan=5)\n",
        "\n",
        "        # self.nnImageOriginal = Image.open(\"images/nn.png\")\n",
        "        # self.resizeAndSetImage(self.nnImageOriginal)\n",
        "\n",
        "        # self.twitter = Label(self.root, text=\"@salvacorts\", cursor=\"hand2\")\n",
        "        # self.twitter.bind(\"<Button-1>\", self.openTwitter)\n",
        "        # self.twitter.grid(row=4, column=6)\n",
        "        # self.github = Label(self.root, text=\"github.com/salvacorts\", cursor=\"hand2\")\n",
        "        # self.github.bind(\"<Button-1>\", self.openGitHub)\n",
        "        # self.github.grid(row=5, column=6)\n",
        "\n",
        "        self.setup()\n",
        "        self.root.mainloop()\n",
        "\n",
        "        # def openTwitter(self, event):\n",
        "        # webbrowser.open_new(r\"https://twitter.com/salvacorts\")\n",
        "\n",
        "        # def openGitHub(self, event):\n",
        "        # webbrowser.open_new(r\"https://www.github.com/salvacorts\")\n",
        "\n",
        "    def resizeAndSetImage(self, image):\n",
        "        size = (drawing_size, drawing_size)\n",
        "        resized = image.resize(size, Image.ANTIALIAS)\n",
        "        self.nnImage = ImageTk.PhotoImage(resized)\n",
        "        self.image.delete(\"IMG\")\n",
        "        self.image.create_image(0, 0, image=self.nnImage, anchor=NW, tags=\"IMG\")\n",
        "\n",
        "    def setup(self):\n",
        "        self.old_x = None\n",
        "        self.old_y = None\n",
        "        self.line_width = self.DEFAULT_PEN_SIZE\n",
        "        self.color = self.DEFAULT_COLOR\n",
        "        self.eraser_on = False\n",
        "        self.c.bind(\"<B1-Motion>\", self.paint)\n",
        "        self.c.bind(\"<ButtonRelease-1>\", self.reset)\n",
        "\n",
        "    def Predict(self):\n",
        "        self.c.postscript(file=\"images/tmp.ps\")\n",
        "        img = Image.open(\"images/tmp.ps\")\n",
        "        img.save(\"images/out.png\", \"png\")\n",
        "\n",
        "        prediction, scores = self.model.Predict(\"images/out.png\")\n",
        "\n",
        "        self.predictionLabel.delete(1.0, END)\n",
        "        self.predictionScores.delete(1.0, END)\n",
        "\n",
        "        img = Image.open(\"images/current.png\")\n",
        "        self.resizeAndSetImage(img)\n",
        "\n",
        "        n = 0\n",
        "        self.predictionLabel.insert(END, \"This is a {}\".format(prediction))\n",
        "        for score in scores:\n",
        "            self.predictionScores.insert(END, \"{}: {}\\n\".format(n, score))\n",
        "            n += 1\n",
        "\n",
        "    def use_eraser(self):\n",
        "        self.predictionLabel.delete(1.0, END)\n",
        "        self.predictionScores.delete(1.0, END)\n",
        "        self.c.delete(\"all\")\n",
        "        self.resizeAndSetImage(self.nnImageOriginal)\n",
        "\n",
        "    def paint(self, event):\n",
        "        self.line_width = self.DEFAULT_PEN_SIZE\n",
        "        paint_color = \"white\" if self.eraser_on else self.color\n",
        "        if self.old_x and self.old_y:\n",
        "            self.c.create_line(\n",
        "                self.old_x,\n",
        "                self.old_y,\n",
        "                event.x,\n",
        "                event.y,\n",
        "                width=self.line_width,\n",
        "                fill=paint_color,\n",
        "                capstyle=ROUND,\n",
        "                smooth=TRUE,\n",
        "                splinesteps=36,\n",
        "            )\n",
        "        self.old_x = event.x\n",
        "        self.old_y = event.y\n",
        "\n",
        "    def reset(self, event):\n",
        "        self.old_x, self.old_y = None, None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ge = Paint()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}